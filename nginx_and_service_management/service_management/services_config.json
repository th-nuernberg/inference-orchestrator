{
    "Services":
    [
        {
            "name": "LLM-Vicuna-13b",
            "ssh_username": "simicch",
            "ssh_key_file": "/app/ssh/ssh_20221208_cs",
            "remote_host": "ml2.informatik.fh-nuernberg.de",
            "remote_port": 8083,
            "local_host": "localhost",
            "local_port": 8083,
            "bash_file": "/nfs/scratch/staff/simicch/03_LLM/01_TGI_ml2/text-generation-inference/run_vicuna_varPort_ml2.sh",
            "check_health_path": "health",
            "timeout": 120,
            "route_name": "llm_service",
            "api_paths": [
                "/",
                "/generate",
                "/generate_stream",
                "/health",
                "/info",
                "/metrics",
                "/tokenize",
                "/chat_completions"
            ]
        }
    ]
}
